{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "The <b>goal</b> of this notebook is to show you how you can <b>train your own model</b> to <b>classify images of your chosen categories</b>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation of the programming environment\n",
    "\n",
    "First things first, let's initiate a few libraries that we need during our analyis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Setup Google Colab by running this cell {display-mode: \"form\"}\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    \n",
    "    # Clone GitHub repository\n",
    "    !git clone https://github.com/miykael/amld20_classification.git\n",
    "        \n",
    "    # Copy files required to run the code\n",
    "    !cp -r 'amld20_classification/downloads' 'amld20_classification/utils.py' .\n",
    "    \n",
    "    # Install packages via pip\n",
    "    !pip install -r \"amld20_classification/colab-requirements.txt\"\n",
    "    \n",
    "    # Restart Runtime\n",
    "    import os\n",
    "    os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in sys.modules:\n",
    "    %tensorflow_version 2.x\n",
    "%run utils.py\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Define Class Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of class labels used for the classifcation\n",
    "class_labels = [\n",
    "               'brown bear',\n",
    "               'polar bear',\n",
    "               'giant panda',\n",
    "               'red panda',\n",
    "               'lion',\n",
    "               'tiger',\n",
    "               'racoon',\n",
    "               'red fox',\n",
    "               ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Note</b>: Feel free to change the list of class labels above as you want. It is recommended to have something between 4-8 classes.\n",
    "    \n",
    "<b>However</b>, for a smooth workshop experience, I recommend to keep the labels that are already listed and to only add a maximum of 4 more labels.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Collect Dataset\n",
    "\n",
    "We will create the dataset for this classification ourselves by using google's image search page. The quickest way to do so is to use the python package [Google Images Download](https://github.com/hardikvasa/google-images-download)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Collect the dataset and load the images\n",
    "imgs_raw = collect_images(class_labels, suffix='photo,close up,portrait')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Note</b>: The parameter <code>suffix='photo,close up,portrait'</code> in the previous function is used to expand our image search requests with additional terms. As it is specified now, the code will look for images for \"brown bear photo\", \"brown bear close up\" and \"brown bear portrait\".\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the data we've collected\n",
    "plot_images(imgs_raw, n_col=8, n_row=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates from the dataset\n",
    "imgs_unique = remove_duplicates(imgs_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Inspect images with their RGB color distributions\n",
    "plot_images(imgs_unique, n_col=8, n_row=3, show_histogram=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Note</b>: For this visualization, we set the parameter <code>show_histogram=True</code> to true, so that the color distributions for Red, Green and Blue are visualized as well. Keep in mind that setting this parameter to true slightly increases the visualization time.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "imgs_clean, imgs_outlier = remove_outliers(imgs_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot clean images\n",
    "plot_images(imgs_clean, n_col=8, n_row=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot outlier images\n",
    "plot_images(imgs_outlier, n_col=8, n_row=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Finalize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "X_pixel, y_pixel, metainfo = create_dataset(imgs_clean, class_labels, img_dim=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many images per class do we have?\n",
    "plot_class_distribution(y_pixel, metainfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does the average image of each class look like?\n",
    "plot_class_average(X_pixel, y_pixel, metainfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does the average RGB color profile look like per class?\n",
    "plot_class_RGB(X_pixel, y_pixel, metainfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract RGB color profiles for each image individually\n",
    "X_rgb, y_rgb = extract_RGB_features(X_pixel, y_pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features according to MobileNet (Neural Network)\n",
    "X_nn, y_nn = extract_neural_network_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Recap before Modeling\n",
    "\n",
    "Each image from our original cleaned dataset is now represented in three different ways:\n",
    "- `X_pixel`: In its original pixel format.\n",
    "- `X_rgb`: Represented by its RGB color profile only.\n",
    "- `X_nn`: Represented by its MobileNet (Neural Network) features\n",
    "\n",
    "To better understand what this means, let's plot an image in these three representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_recap(X_pixel, X_rgb, X_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Modeling and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Fit Model to Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit(X, y, test_size=0.5, alpha_low=-3, alpha_high=5, n_steps=16, cv=2, plot_figures=False):\n",
    "\n",
    "    # Prepare datasets\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    X_temp = X.reshape((len(X), -1))\n",
    "    X_temp = scaler.fit_transform(X_temp)\n",
    "    indexes = list(range(len(X_temp)))\n",
    "\n",
    "    # Split Dataset into training and test set\n",
    "    x_train, x_test, y_train, y_test, idx_train, idx_test = train_test_split(\n",
    "        X_temp, y, indexes, test_size=test_size, random_state=0, stratify=y)\n",
    "\n",
    "    # Model creation\n",
    "    ridge = RidgeClassifier(class_weight='balanced')\n",
    "    alphas = np.logspace(alpha_low, alpha_high, num=n_steps)\n",
    "    clf = GridSearchCV(estimator=ridge,\n",
    "                       param_grid={'alpha': alphas},\n",
    "                       cv=cv, return_train_score=True,\n",
    "                       n_jobs=-1, verbose=1)\n",
    "\n",
    "    # Fit the model to the data\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        start = time.time()\n",
    "        results = clf.fit(x_train, y_train)\n",
    "        comp_time_total = time.time() - start\n",
    "\n",
    "    # Plot the model fit curves\n",
    "    if plot_figures:\n",
    "\n",
    "        # Extract relevant modelling metrics\n",
    "        train_scores = 100 * clf.cv_results_['mean_train_score']\n",
    "        valid_scores = 100 * clf.cv_results_['mean_test_score']\n",
    "        std_tr = 100 * clf.cv_results_['std_train_score']\n",
    "        std_va = 100 * clf.cv_results_['std_test_score']\n",
    "\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.semilogx(alphas, train_scores, label='Training Set')\n",
    "        plt.semilogx(alphas, valid_scores, label='Validation Set')\n",
    "\n",
    "        # Add marker and text for best score\n",
    "        x_pos = clf.best_params_['alpha']\n",
    "        y_pos = 100 * clf.best_score_\n",
    "        txt = '{:0.2f}%'.format(y_pos)\n",
    "        plt.scatter(x_pos, y_pos, marker='x', c='red', zorder=10)\n",
    "        plt.text(x_pos, y_pos - 7.5, txt, fontdict={'size': 18})\n",
    "\n",
    "        # Quantify variance with ±std curves\n",
    "        plt.fill_between(alphas, train_scores-std_tr, train_scores+std_tr, alpha=0.3)\n",
    "        plt.fill_between(alphas, valid_scores-std_va, valid_scores+std_va, alpha=0.3)\n",
    "        plt.title('Model Performance')\n",
    "        plt.ylabel('Classification Accuracy [%]')\n",
    "        plt.xlabel('Model Parameter [alpha]')\n",
    "        \n",
    "        # Adjust x-lim, y-lim, add legend and adjust layout\n",
    "        plt.xlim(10**alpha_low, 10**alpha_high)\n",
    "        plt.ylim(15, 105)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        # Provide written performance feedback\n",
    "        best_score_test = clf.best_score_ * 100\n",
    "        feedback_txt = 'Model trained for {:.2f}s total '.format(comp_time_total)\n",
    "        feedback_txt += 'and reached an accuracy of: {:.2f}%'.format(best_score_test)\n",
    "        time.sleep(0.25)\n",
    "        print(feedback_txt)\n",
    "\n",
    "    # Store everything in model\n",
    "    model = {'model': results.best_estimator_,\n",
    "             'best_score': results.best_score_,\n",
    "             'x_train': x_train,\n",
    "             'x_test': x_test,\n",
    "             'y_train': y_train,\n",
    "             'y_test': y_test,\n",
    "             'idx_train': idx_train,\n",
    "             'idx_test': idx_test}\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_pixel = model_fit(X_pixel, y_pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rgb = model_fit(X_rgb, y_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn = model_fit(X_nn, y_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Check Model Performance on Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "check_model_performance(model_pixel, metainfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_model_performance(model_rgb, metainfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_model_performance(model_nn, metainfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Communication & Reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Investigation of Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose which model to investigate: 'model_pixel', 'model_rgb' or 'model_nn'\n",
    "model = model_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correct predictions\n",
    "investigate_predictions(model, metainfo, show_correct=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot wrong predictions\n",
    "investigate_predictions(model, metainfo, show_correct=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Try out Model Predictions on New Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the URL path to an image that you would like to classify\n",
    "img_url = 'https://live.staticflickr.com/7279/7017467025_8807cc82f6_b.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predict_new_image(img_url, model_nn, metainfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_url = 'https://d33wubrfki0l68.cloudfront.net/067d6b185769f031404e927b1b70de6d5ece3e0a/d82f4/michael.1164620e.jpg'\n",
    "predict_new_image(img_url, model_nn, metainfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_url = 'www.YOUR_OWN_IMAGE.jpg'\n",
    "predict_new_image(img_url, model_nn, metainfo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
