{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<h3>For Google Colab Users</h3>\n",
    "\n",
    "If you are running this notebook on Google Colab, please make sure to do two things:\n",
    "\n",
    "**First**, switch the runtime to a GPU instance. This can be done by clicking on Google Colab on the `Runtime` tab and select the option `Change runtime type`. In the appearing popup window, leave the `Runtime type` on Python 3, but select for `Hardware accelerator` the option **GPU**.\n",
    "\n",
    "**Second**, execute the following code cell to prepare the notebook environment and its dependencies.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    \n",
    "    # Clone GitHub repository\n",
    "    !git clone https://github.com/epfl-exts/amdl20-image-classification.git\n",
    "        \n",
    "    # Copy files required to run the code\n",
    "    !cp -r 'amld20_classification/downloads' 'amld20_classification/utils.py' .\n",
    "    \n",
    "    # Install packages via pip\n",
    "    !pip install -r \"amld20_classification/colab-requirements.txt\"\n",
    "    \n",
    "    # Restart Runtime\n",
    "    import os\n",
    "    os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification\n",
    "\n",
    "The **goal** of this hands-on exercise is to provide a general overview of image classifiation and to show you how you can **train a model** and later use it to **classify images** according to your own categories.\n",
    "\n",
    "The whole process is subdivided into 4 sections:\n",
    "\n",
    "1. **Data Preparation**: Collect the data, clean it and prepare it for further analysis.\n",
    "\n",
    "\n",
    "2. **Data Exploration**: Explore the dataset and modify it to your need.\n",
    "\n",
    "\n",
    "3. **Data Modeling and Analysis**: Model creation, optimization & evaluation. \n",
    "\n",
    "\n",
    "4. **Results Discussion & Exploration**: Investigate model performance and understand results.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Note</b>: The full code to this hands-on exercise can be found under <a href=\"https://github.com/epfl-exts/amdl20-image-classification\">github.com/epfl-exts/amdl20-image-classification</a>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation of the programming environment\n",
    "\n",
    "First things first, let's initiate a few libraries that we need during our analyis. The exact details of these statements are not important, but in short: We're preparing all the functions we would like to use and make sure that the plotting of the figures looks nice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    %tensorflow_version 2.x\n",
    "%run utils.py\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preparation\n",
    "\n",
    "The goal of this section is to (1) define the categories we want to predict, and to make sure that (2) the data is collected, (2) cleaned and (3) loaded into a useful and accessible data format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Define Class Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h3>Task 1 (after completing the exercise at least once)</h3>\n",
    "\n",
    "Feel free to change the list of class labels below as you like. For this hands-on exercise it is recommended to have something between 3-8 classes.\n",
    "\n",
    "**However**, each new class will take some time to be downloaded! Therefor, to provide a smooth workshop experience, I recommend to keep the class label list as it is and only explore different classes in at a later stage.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of class labels to use for the image classification\n",
    "class_labels = [\n",
    "               'brown bear',\n",
    "               'polar bear',\n",
    "               'giant panda',\n",
    "               'red panda',\n",
    "               'lion',\n",
    "               'tiger',\n",
    "               'racoon',\n",
    "               'red fox',\n",
    "               ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Collect Dataset\n",
    "\n",
    "In an ideal case you would collect the data yourself, make sure that it is of high quality and can be used for an image classification project. In the scope of this hands-on exercise we don't have the time for that so we will take a few short cuts.\n",
    "\n",
    "First, we will use the python package [Google Images Download](https://github.com/hardikvasa/google-images-download) to download images of our target classes directly via google's image search service. However, this library only allows the download of max. 100 images at once. To bypass this restriction we will look for our class labels, multiple times, each time with an additional keyword.\n",
    "\n",
    "So, instead just looking for images of a \"brown bear\", we can look for \"brown bear close up\" and \"brown bear portrait\" images. This is exactly what we will do with the parameter `search_suffix` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define additional search temrs to expand the number of searches\n",
    "search_suffix = ',close up,portrait'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the class labels and the additional search terms are defined, we can go ahead and collect the images from the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset and store the images on disk\n",
    "imgs_raw = collect_images(class_labels, suffix=search_suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once all the images are downloaded and the file names are stored in the `imgs_raw` variable, we can go ahead and take a look at a few of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the data we've collected\n",
    "plot_images(imgs_raw, n_col=10, n_row=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h3>Note</h3>\n",
    "\n",
    "All the images above are squared, i.e. have the same number of pixels in width and height. This is done on purpose, to make all photos \"equal\" and comparable. This restriction means that some of the images that originally were rectangular, were cropped to a squared shape - which explains why some of the images seem to be cutting of the imporant part of the image.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Clean Dataset\n",
    "\n",
    "Almost all datasets are to a certain degree \"dirty\" and need to be cleaned. Cleaning in the context of classification means to:\n",
    "- remove duplicate samples\n",
    "- remove outliers or extreme values that are not part of the target class\n",
    "- hanlde missing values\n",
    "\n",
    "We don't have any missing values in these dataset (images are either downloaded or not), and we will therefore only focus on the first two points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates from the dataset\n",
    "imgs_unique = remove_duplicates(imgs_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Outliers\n",
    "\n",
    "The removal of outliers is a bit more tricky when it comes to images. Ideally you would do this by hand and make sure that you only have meaningful images in your dataset, which only correspond to the chosen class labels. For this hands-on exercise, a manual check-up is not possible, so let's try a shortcut.\n",
    "\n",
    "Each image has a particular color profile, i.e. distribution of red, green and blue (RGB) pixel values. Looking at these particular RGB value distributions might allow us to differentiate photos of animals from photoshopped images, gray colored ones or graphical logos. Let's take a closer look at a few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot images together with their RGB color distributions\n",
    "plot_images(imgs_unique, n_col=8, n_row=2, show_histogram=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To remove outlier images from the dataset, we will take a look at the RGB color profile of each image and remove images that either are only in gray colors or that have sudden extreme spikes in the RGB profile (i.e. images that have huge amounts of pixels with the exact same color value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers from the dataset\n",
    "imgs_clean, imgs_outlier = remove_outliers(imgs_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we separated the dataset into clean and outlier images, let's take a closer look at them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot some outlier images\n",
    "plot_images(imgs_outlier, n_col=10, n_row=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some clean images\n",
    "plot_images(imgs_clean, n_col=10, n_row=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Finalize Dataset\n",
    "\n",
    "As a last step in the **data preparation** section, we need to finalize the actual dataset and store the relevant image information into useful variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h3>Task 2 (after completing the exercise at least once)</h3>\n",
    "\n",
    "The image dimension of 32 was chosen as a trade-off between speed and detail. To better understand the effect of this trade-off we recommend you to explore different values for <code>img_dim=32</code>. What happens if you set this number to 16, 64 or even 128?\n",
    "\n",
    "**Note**: Changing this parameter will also have an effect on the computation time. For this reason we recommend that during the first walk through of this hands-on that you leave this parameter at <code>img_dim=32</code>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "X_pixel, y_pixel, metainfo = create_dataset(imgs_clean, class_labels, img_dim=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h3>Note</h3>\n",
    "\n",
    "**Note 1:** In machine learning, the variable <code>X</code> is usually used as the dataframe, i.e. the feature matrix and the variable <code>y</code> is used as the label for the target. Here we've added an additional variable called <code>metainfo</code> that contains relevant information about the dataset (e.g. size of dataset, class labels, image filenames, etc.) which are needed for the code further below.\n",
    "\n",
    "**Note 2:** The function <code>create_dataset</code> above also contains the parameter <code>img_dim=32</code>, which specified to which pixel resolution the images should be resampled. In this case, <code>32</code> means that all images are resized to a pixel resolution of 32 x 32. Downsampling images from their original size to a size of 32 x 32 reduces the computation time, and makes sure that all images have the same size.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Exploration\n",
    "\n",
    "Once the dataset is ready to use, it is important that we make sure that we understand its properties. This can be done by doing something called an **Explorative Data Analysis** or short EDA. Each of these EDA steps should lead to an observation and a decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Data Description\n",
    "\n",
    "So, first things first, let's take a closer look at our dataset and describe it's basic properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many images per class do we have?\n",
    "plot_class_distribution(y_pixel, metainfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**: The classes are not equally distributed. Some classes have more than twice as many images than others.  \n",
    "**Decision**: The unbalanced occurence of the different classes needs to be considered during the data modeling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do the average images of each class look like?\n",
    "plot_class_average(X_pixel, y_pixel, metainfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**: Some classes like `giant_panda`, `polar_bear` and `red_panda` have very unique color characteristics.  \n",
    "**Decision**: Let's take a closer look at the RGB color distribution of the average images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does the average RGB color profile look like per class?\n",
    "plot_class_RGB(X_pixel, y_pixel, metainfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**: The individual RGB color distributions between almost all classes looks different.  \n",
    "**Decision**: We should use the RGB color profile as a data feature for the image classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Feature Engineering\n",
    "\n",
    "From the previous section, we know that the RGB color profile of each image might be useful to do the image classification. For this reason, let's take the first dataset `X_pixel` and create a second dataset called `X_rgb` that consists only of the RGB color profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract RGB color profiles for each image individually\n",
    "X_rgb, y_rgb = extract_RGB_features(y_pixel, metainfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to using the RGB color profile as new data features, let's also try to extract meaningful features from the images by using a state of the art neural network called [MobileNet](https://arxiv.org/abs/1704.04861). **Note**, the neural network that we will use for this feature extraction will be downloaded directly from [Tensorflow Hub](https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Extract features according to MobileNet (Neural Network)\n",
    "X_nn, y_nn = extract_neural_network_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Recap before Data Modeling\n",
    "\n",
    "Before we continue with the next section, let's quickly recap the three different ways in which we've represented our images:\n",
    "- `X_pixel`: This dataset contains the original data in its raw form. Each value is a RGB pixel value in the original image.\n",
    "- `X_rgb`: This dataset contains the RGB color profile of each image.\n",
    "- `X_nn`: This dataset contains an N-dimensional feature vectore per image, extracted with the neural network structure, called MobileNet.\n",
    "\n",
    "To better understand what this means, let's plot an image in these three representations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_recap(X_pixel, X_rgb, X_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Modeling and Analysis\n",
    "\n",
    "Once the data is (1) collected, cleaned, and prepared and (2) meaningfull features are prepared - we are ready for the data modeling. We will optimize the model fitting once for each kind of dataset, i.e. `X_pixel`, `X_rgb` and `X_nn`.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**More indepth information about the classifier:** The model used in this hands-on example is a [Ridge Regression Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifier.html). Ridge regression has the advantage of being rather quick, while also allowing us the fine tuning of a regularization parameter alpha for optimal data fitting. During model optimization, we will be using a crossvalidation approach with 4 folds to fine tune the hyperparameter. To allow to test for generalization, the dataset is initially split into a training and test set according to a 50/50 ratio. Because of the unequal distribution of the class labels throughout the dataset a weighted balancing approach during model optimization is applied.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Model Fitting on `X_pixel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train a model fit to the data in pixel format\n",
    "model_pixel = model_fit(X_pixel, y_pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigation of the model performance\n",
    "check_model_performance(model_pixel, metainfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Model Fitting on `X_rgb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a model fit to the data in rgb format\n",
    "model_rgb = model_fit(X_rgb, y_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigation of the model performance\n",
    "check_model_performance(model_rgb, metainfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Model Fitting on `X_nn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a model fit to the data in neural network format\n",
    "model_nn = model_fit(X_nn, y_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigation of the model performance\n",
    "check_model_performance(model_nn, metainfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Results Discussion & Exploration\n",
    "\n",
    "Once the model was optimized and the general model performance was investigated, we should take a closer look at the results. Why did the model predict a given class? With what certainty was this decision made? Which images did the model missclassify and why? Which images are easy for the model to classify? ...\n",
    "\n",
    "This are all questions we should investigate, once the model is trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Investigation of Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h3>Task 3</h3>\n",
    "\n",
    "The `model_nn` should lead to the best results. Nonetheless, try to investigate the model performance for the `model_pixel` and `model_rgb` as well by changing the variable name in the following cell.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose which model to investigate: 'model_pixel', 'model_rgb' or 'model_nn'\n",
    "model = model_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see which images the model did correctly classify and how certain it was:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correct predictions\n",
    "investigate_predictions(model, metainfo, show_correct=True, nimg=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see which images the model did not correctly classify and how wrong it was:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot wrong predictions\n",
    "investigate_predictions(model, metainfo, show_correct=False, nimg=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Use pretrained model to predict class probabilities on a new image from the web\n",
    "\n",
    "The training of the model can be very computational intensive. But once the model is trained, we can use it to very quickly predict the class properties of any other image we give it.\n",
    "\n",
    "So, let's take an image from the web and see how well the trained model performs on a new image!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the class properties of an image from the web\n",
    "img_url = 'https://c402277.ssl.cf1.rackcdn.com/photos/18134/images/hero_small/Medium_WW226365.jpg?1574452099'\n",
    "predict_new_image(img_url, model_nn, metainfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about an image that is only slightly related to the target classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the class properties of an image from the web\n",
    "img_url = 'https://live.staticflickr.com/7279/7017467025_8807cc82f6_b.jpg'\n",
    "predict_new_image(img_url, model_nn, metainfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about me? What kind of an animal am I?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the class properties of another image from the web\n",
    "img_url = 'https://d33wubrfki0l68.cloudfront.net/067d6b185769f031404e927b1b70de6d5ece3e0a/d82f4/michael.1164620e.jpg'\n",
    "predict_new_image(img_url, model_nn, metainfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h3>Task 4</h3>\n",
    "    \n",
    "Choose your own image from the internet, indicate the URL link to the image under `img_url` and run the following cell.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_url = 'www.YOUR_OWN_IMAGE.jpg'\n",
    "predict_new_image(img_url, model_nn, metainfo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
